# 刮网入门

> 原文:[https://www.geeksforgeeks.org/introduction-to-web-scraping/](https://www.geeksforgeeks.org/introduction-to-web-scraping/)

网页抓取是一种从网站获取数据的技术。在网上冲浪时，许多网站不允许用户保存数据供个人使用。一种方法是手动复制粘贴数据，这既繁琐又耗时。网页抓取是从网站提取数据过程的自动化。这项活动是在称为刮网器的刮网软件的帮助下完成的。他们根据用户需求自动从网站加载和提取数据。这些可以定制为一个网站，也可以配置为任何网站。

**刮网的用途:**刮网在专业和个人层面都有很多用途。不同层次有不同的需求，网页抓取的一些流行用法是。

*   **Brand monitoring and competition analysis:** Web page crawling is used to get feedback from customers on specific services or products, so as to know how customers feel about the specific things. It is also used to extract competitor's data in a structured and usable format.
*   **Machine learning:** Machine learning is a process of artificial intelligence, in which the machine is allowed to learn and improve with its experience instead of being explicitly programmed. Therefore, it is necessary to extract a large amount of data from millions of websites through web crawling software.
*   **Financial data analysis:** Web crawling is used to save the records of the stock market in a usable format, and therefore it is used for insight.
*   **Social media analysis:** It is used to extract data from social media websites to measure customer trends and their reactions to activities.
*   **SEO 监控:**搜索引擎优化是一个网站在 Google、Yahoo、Bing 等不同搜索引擎中的可见性和排名的优化。网页抓取是用来了解内容的排名是如何随时间变化的。

    还有很多其他的原因可以使用网络报废。

**网页抓取技术:**从网站中提取数据有两种方式，手动提取技术和自动提取技术。

*   **Manual extraction technology:** Manually copying and pasting website content belongs to this technology. Although cumbersome, time-consuming and repetitive, it is an effective method to clear data from sites with good scratch-resistant measures (such as bot detection).
*   **Automatic extraction technology:** Web page capture software is used to automatically extract data from the website according to user's requirements.
    *   **HTML parsing:** Parsing means to analyze what can be understood part by part. In other words, it means converting one form of information into another form that is easier to handle. HTML parsing refers to receiving code and extracting relevant information from it according to users' requirements. Mainly using JavaScript, the target is HTML page as the name implies.
    *   **DOM parsing:** Document object model is the official recommendation of the World Wide Web Consortium. It defines an interface that enables users to modify and update the style, structure and content of XML documents.
    *   **Web page crawling software:** Nowadays, many Web page crawling tools are available, or customized according to the needs of users to extract the required information from millions of websites.

**刮网工具:**刮网工具是专门为从互联网上提取数据而开发的。也被称为网络收集工具或数据提取工具，它们对任何试图从网站收集特定数据的人都很有用，因为它们为用户提供了从多个网站提取数据的结构化数据。一些最流行的网页抓取工具有:

*   Import.io
*   Webhose.io
*   Dexi.io
*   剪贴簿
*   Parsehub

**刮网合法化:**刮网合法化是一个敏感话题，取决于它的使用方式，它可能是好事，也可能是坏事。一方面，用好的 bot 进行网页抓取，使搜索引擎能够索引网页内容，提供比价服务，为客户节省资金和价值。但是网页抓取可以被重新定位，以满足更多的恶意和滥用的目的。网页抓取可以与其他形式的恶意自动化相结合，被命名为*“坏机器人”*，这使得其他有害活动成为可能，如*拒绝服务攻击*、*竞争数据挖掘*、*账户劫持*、*数据窃取*等。

网页抓取的合法性是一个灰色区域，随着时间的推移，它会不断发展。尽管网络抓取器在技术上提高了数据浏览、加载、复制和粘贴的速度，但网络抓取也是侵犯版权、违反使用条款和其他对公司业务造成高度破坏的活动案件增加的罪魁祸首。

**对刮网的挑战:**除了对刮网合法性的挑战，还有其他问题对刮网提出了挑战。

*   **Data warehouse:** Large-scale data extraction will generate a large amount of information for storage. If the data warehouse infrastructure is not properly constructed, searching, storing and exporting these data will become a troublesome task. Therefore, for large-scale data extraction, a perfect data warehouse system without any defects and faults is needed.
*   **Changes in website structure:** Every website will regularly update the user interface to enhance its attraction and experience. This also requires various structural changes. Because the web crawler is set according to the code elements of the website at that time, it also needs to be modified. Therefore, they also require weekly changes to capture data for the correct website, because incomplete information about the website structure will lead to incorrect data capture.
*   **Scratch-proof technology:** Some websites use scratch-proof technology to prevent any scratch attempt. They apply dynamic coding algorithm to prevent any robot from interfering, and use IP blocking mechanism. It takes a lot of time and money to work around this anti-scratch technology.
*   **Data quality extracted:** Records that do not meet the information quality requirements will affect the overall integrity of data. It is an arduous task to ensure that the collected data meet the quality standards, because it needs to be completed in real time.

**数据刮擦的未来:**由于数据刮擦存在一些挑战和机遇，可以公平地认为，非预期的数据刮擦从业者倾向于制造道德风险，他们将公司作为目标并检索其数据。然而，由于我们正处于数据转型的边缘，数据抓取与大数据相结合可以为公司提供市场情报，帮助他们识别关键趋势和模式，并确定最佳机会和解决方案。因此，说数据清理可以很快升级到更好的状态并没有错。